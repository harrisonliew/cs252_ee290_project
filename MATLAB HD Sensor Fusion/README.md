# HDC-MER
To interact naturally and achieve mutual sympathy between humans and machines, emotion recognition is one of the most  important  function  to  realize  advanced  human-computer interaction devices. Due to the high correlation between emotionand  involuntary  physiological  changes,  physiological  signals  area  prime  candidate  for  emotion  analysis.  However,  due  to  the need  of  a  huge  amount  of  training  data  for  a  high-quality machine  learning  model,  computational  complexity  becomes  amajor  computational  bottleneck.  To  overcome  this  issue,  brain-inspired  hyperdimensional  (HD)  Computing,  an  energy-efficientand  fast  learning  computational  paradigm,  has  a  high  potentialto  achieve  a  computational  balance  between  accuracy  and  the amount  of  training  data.  We  propose  an  HD  Computing-based Multimodality  Emotion  Recognition  (HDC-MER).  HDC-MER maps real-valued features to binary HD vectors using a random nonlinear function, and further encodes them over time, and fuses across different modalities including GSR, ECG, and EEG.

Citation:
En-Jui Chang, Abbas Rahimi, Luca Benini, and An-Yeu (Andy) Wu, “Hyperdimensional Computing-based Multimodality Emotion Recognition with Physiological Signals,” in Proc. IEEE International Conference on Artificial Intelligence Circuits and Systems (AICAS 2019), March 2019.
